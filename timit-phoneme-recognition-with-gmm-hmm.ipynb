{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change paths as appropriate, all files are in the repo. The dataset is shared at below link,\n",
    "\n",
    "https://drive.google.com/drive/folders/1cztOSY24ndvBhcmjuJaPuMSIdgy04Rjg?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-11T00:40:07.942847Z",
     "iopub.status.busy": "2021-12-11T00:40:07.942264Z",
     "iopub.status.idle": "2021-12-11T00:40:09.938011Z",
     "shell.execute_reply": "2021-12-11T00:40:09.936595Z",
     "shell.execute_reply.started": "2021-12-11T00:40:07.942719Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle as pkl\n",
    "import gc\n",
    "import librosa\n",
    "from librosa import display\n",
    "import math\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from hmmlearn.hmm import GMMHMM\n",
    "\n",
    "path = 'C:/Users/shukl/Documents/Georgia-Tech/MUSI-6201/Project on Music Segmentation/TIMIT-GMMHMM/Dataset'\n",
    "data_path = path+\"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T00:40:12.955758Z",
     "iopub.status.busy": "2021-12-11T00:40:12.955110Z",
     "iopub.status.idle": "2021-12-11T00:40:13.014333Z",
     "shell.execute_reply": "2021-12-11T00:40:13.013268Z",
     "shell.execute_reply.started": "2021-12-11T00:40:12.955602Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureCollection():\n",
    "    __train_desc = 'train_data.csv'\n",
    "    __test_desc = 'test_data.csv'\n",
    "    __data_directory = './data'\n",
    "    __main_directory = './'\n",
    "    \n",
    "    # path to csv files\n",
    "    f_Path = 'path_from_data_dir' \n",
    "    \n",
    "    isAudio = 'is_converted_audio'  #boolean field that tells that the record in train_data.csv contains the description of audio file we are interested in\n",
    "    isPhon = 'is_phonetic_file'\n",
    "    \n",
    "    lengthOfWindow = 0.025\n",
    "    stepWindow = 0.01\n",
    "    \n",
    "    \n",
    "    def __init__(self,path=None):\n",
    "        \n",
    "        self.__main_directory = path\n",
    "        \n",
    "        if path[len(path)-1] == '/':\n",
    "            self.__data_directory = path+\"data/\"\n",
    "        else:\n",
    "            self.__main_directory += \"/\"\n",
    "            self.__data_directory = self.__main_directory+\"data/\"\n",
    "      \n",
    "        # Mapping 61 phoneme to 39 phonemes\n",
    "        self.phon61_map39 = {\n",
    "            'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n",
    "            'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n",
    "            'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n",
    "            'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n",
    "            'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n",
    "            'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n",
    "            'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n",
    "            'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#' \n",
    "        }\n",
    "        \n",
    "        self.phon_61 = list(self.phon61_map39.keys())\n",
    "        self.phon_39 = list(set(self.phon61_map39.values()))\n",
    "        self.phon_61.sort()\n",
    "        self.phon_39.sort()\n",
    "\n",
    "        self.label_p39 = {}\n",
    "        self.p39_label = {}\n",
    "        for idx,phon in enumerate(self.phon_39):\n",
    "            self.label_p39[phon] = idx\n",
    "            self.p39_label[idx] = phon\n",
    "\n",
    "        self.phon39_map61 = {}\n",
    "        for p61,p39 in self.phon61_map39.items():\n",
    "            if not p39 in self.phon39_map61:\n",
    "                self.phon39_map61[p39] = []\n",
    "            self.phon39_map61[p39].append(p61)\n",
    "        \n",
    "        pkl.dump(self.label_p39,open('/timit-gmmhmm/phon_label_index.pkl','wb'))\n",
    "        pkl.dump(self.phon61_map39,open('/timit-gmmhmm/phon_map_61To39.pkl','wb'))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get39EquiOf61(self,p):\n",
    "        return self.phon61_map39[self.removePhonStressMarker(p)]\n",
    "    \n",
    "    \n",
    "    def get39Index(self,phon):\n",
    "        return self.label_p39[phon]\n",
    "    \n",
    "\n",
    "    def get39Phon(self,index):\n",
    "        return self.p39_label[index] \n",
    "\n",
    "    \n",
    "    def removePhonStressMarker(self,phon):\n",
    "        phon = phon.replace('1','')\n",
    "        phon = phon.replace('2','')\n",
    "        return phon\n",
    "    \n",
    "    \n",
    "    def getWindow(self,sr):\n",
    "        nfft = 512\n",
    "        winlen = self.lengthOfWindow * sr\n",
    "        winstep = self.stepWindow * sr\n",
    "        return nfft,int(winlen),int(winstep)\n",
    "    \n",
    "        \n",
    "    def readTrainingDataDescriptionCSV(self):\n",
    "        file_path = self.__main_directory + 'train_data.csv' #check if train_data.csv is in correct path\n",
    "        # Tdd -> training data descriptions\n",
    "        self._Tdd = pd.read_csv(file_path)\n",
    "        # removing NaN entries in the train_data.csv file\n",
    "        dr = ['DR1','DR2','DR3','DR4','DR5','DR6','DR7','DR8']\n",
    "        self._Tdd = self._Tdd[self._Tdd['dialect_region'].isin(dr)]\n",
    "        return self._Tdd\n",
    "\n",
    "    \n",
    "    def readTestingDataDescriptionCSV(self):\n",
    "        file_path = self.__main_directory + 'test_data.csv' #check if train_data.csv is in correct path\n",
    "        # tdd -> testing data descriptions\n",
    "        self._tdd = pd.read_csv(file_path)\n",
    "        # removing NaN entries in the train_data.csv file\n",
    "        dr = ['DR1','DR2','DR3','DR4','DR5','DR6','DR7','DR8']\n",
    "        self._tdd = self._tdd[self._tdd['dialect_region'].isin(dr)]\n",
    "        return self._tdd\n",
    "    \n",
    "    \n",
    "    def getListAudioFiles(self,of='Train'):\n",
    "        if of == 'Train':\n",
    "            self.readTrainingDataDescriptionCSV()\n",
    "            return self._Tdd[self._Tdd[self.isAudio] == True]\n",
    "        if of == 'Test':\n",
    "            self.readTestingDataDescriptionCSV()\n",
    "            return self._tdd[self._tdd[self.isAudio] == True]\n",
    "        \n",
    "        \n",
    "    def getListPhonemeFiles(self,of='Train'):\n",
    "        if of == 'Train':\n",
    "            self.readTrainingDataDescriptionCSV()\n",
    "            return self._Tdd[self._Tdd[self.isPhon] == True]\n",
    "        if of == 'Test':\n",
    "            self.readTestingDataDescriptionCSV()\n",
    "            return self._tdd[self._tdd[self.isPhon] == True]\n",
    "        \n",
    "               \n",
    "    def readAudio(self,fpath=None,pre_emp = False):\n",
    "        if(fpath == None):\n",
    "            return np.zeros(1),0\n",
    "        \n",
    "        fpath = self.__data_directory+fpath\n",
    "        if os.path.exists(fpath):\n",
    "            S,sr = librosa.load(fpath,sr=None)\n",
    "            if pre_emp:\n",
    "                S = librosa.effects.preemphasis(S)\n",
    "            return S,sr   \n",
    "        else:\n",
    "            return np.zeros(1),0\n",
    "        \n",
    "    \n",
    "    def getPhonPathFromAudioPath(self,audio_path):\n",
    "        return audio_path.split(\".WAV\")[0]+\".PHN\"\n",
    "    \n",
    "    \n",
    "    def readPhon(self,fpath=None):    \n",
    "        if(fpath == None):\n",
    "            raise Exception('phon file path not provided')\n",
    "            \n",
    "\n",
    "        fpath = data_path+fpath\n",
    "        ph_ = pd.read_csv(fpath,sep=\" \")\n",
    "        first = ph_.columns\n",
    "        ph_.columns = ['start','end','phoneme']\n",
    "        ph_.loc[-1] = [int(first[0]),int(first[1]),first[2]]\n",
    "        ph_ = ph_.sort_index()\n",
    "        ph_.index = range(ph_.index.shape[0])\n",
    "        return ph_\n",
    "        \n",
    "        \n",
    "    def getFeatureAndLabel(self,ftype='mfcc',audio_path=None,phon_path=None,n_mels=128,delta=False,delta_delta=False):\n",
    "        if audio_path == None:\n",
    "            raise Exception(\"Path to audio (Wav) file must be provided\")\n",
    "        wav,sr = self.readAudio(fpath=audio_path,pre_emp=True)\n",
    "        nfft,winlen,winstep = self.getWindow(sr)\n",
    "        if(ftype == 'mfcc'):\n",
    "            db_melspec = librosa.feature.mfcc(wav,sr=sr,hop_length=winstep,win_length=winlen,n_fft=nfft,n_mfcc=n_mels)\n",
    "            \n",
    "        mD = None\n",
    "        mDD = None\n",
    "        if(delta):\n",
    "            mD = librosa.feature.delta(db_melspec)\n",
    "            db_melspec = np.concatenate([db_melspec,mD])\n",
    "            if(delta_delta):\n",
    "                mDD = librosa.feature.delta(mD)\n",
    "                db_melspec = np.concatenate([db_melspec,mDD])\n",
    "        \n",
    "        audio_phon_transcription = None\n",
    "        if phon_path == None:\n",
    "            phon_path = self.getPhonPathFromAudioPath(audio_path)\n",
    "            \n",
    "        audio_phon_transcription = self.readPhon(phon_path)     \n",
    "        \n",
    "        feature_vectors = []\n",
    "        db_melspec = db_melspec.T       \n",
    "        time = db_melspec.shape[0]\n",
    "        \n",
    "        prev = None\n",
    "        labels = []\n",
    "        for i in range(time):\n",
    "            #---collecting feature---\n",
    "            feature_vectors.append(db_melspec[i])\n",
    "            \n",
    "            #---collecting phoneme label ---\n",
    "            start = winstep * i\n",
    "            end = start+winlen\n",
    "            diff = start+400\n",
    "            phoneme = list(\n",
    "                        audio_phon_transcription[\n",
    "                            ((audio_phon_transcription['start']<=start) & \n",
    "                            ((audio_phon_transcription['end']-start)>=int(winlen/2)))\n",
    "                            |\n",
    "                            ((audio_phon_transcription['start']<=end) & \n",
    "                                (audio_phon_transcription['end']>end))  \n",
    "                        ].to_dict()['phoneme'].values()\n",
    "            )\n",
    "            tmp = phoneme\n",
    "            try:\n",
    "                phoneme = self.get39EquiOf61(phoneme[0])\n",
    "                prev = phoneme\n",
    "                labels.append(phoneme)\n",
    "            except:\n",
    "                # if the phoneme file doesn't start from Zero, then assign 'h#' silent to the frames in those unlabeled segments\n",
    "                # or if the phoneme can't be determined as per logic above for a segment then assign silent 'h#'\n",
    "                labels.append('h#')\n",
    "             \n",
    "        return feature_vectors,labels\n",
    "                \n",
    "        \n",
    "    def prepareLabelsForTraining(self,labels):\n",
    "        print('Preparing Labels')\n",
    "        label_vector = []\n",
    "        p_bar = tqdm(range(len(labels)))\n",
    "        c = 0\n",
    "        for l in labels:\n",
    "            label = [0 for i in range(39)]\n",
    "            label[self.label_p39[l]-1] = 1\n",
    "            label_vector.append(label)\n",
    "            c+=1\n",
    "            if c == 500:\n",
    "                p_bar.set_description(f'Working on phoneme {l}')\n",
    "                p_bar.update(c)\n",
    "                c = 0\n",
    "           \n",
    "        p_bar.set_description(f'Working on phoneme {l}')\n",
    "        p_bar.update(c) \n",
    "        return label_vector\n",
    "    \n",
    "        \n",
    "    def collectHMMFeatures(self,ft='Train',ftype='mfcc',n_mels=128,delta=False,delta_delta=False):\n",
    "        tddA = self.getListAudioFiles(ft)\n",
    "        tddA.index = range(tddA.shape[0])\n",
    "        feature_vectors = [[] for i in range(39)]\n",
    "        lengths = [[] for i in range(39)]\n",
    "        \n",
    "        p_bar = tqdm(range(tddA.shape[0]))\n",
    "        for i in range(tddA.shape[0]):\n",
    "            p_bar.set_description(f'Working on {tddA.loc[i][self.f_Path]}')\n",
    "            fv,lv = self.getFeatureAndLabel(ftype=ftype,audio_path=tddA.loc[i][self.f_Path],n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n",
    "            count = 0\n",
    "            prev = ''\n",
    "            for j in range(len(lv)):\n",
    "                if prev == '' or lv[j]==prev:\n",
    "                    prev = lv[j]\n",
    "                    count+=1\n",
    "                    feature_vectors[self.get39Index(prev)].append(fv[j])\n",
    "                elif lv[j]!=prev:\n",
    "                    lengths[self.get39Index(prev)].append(count)\n",
    "                    prev = lv[j]\n",
    "                    feature_vectors[self.get39Index(prev)].append(fv[j])\n",
    "                    count = 1\n",
    "                    \n",
    "            #inserting last length\n",
    "            lengths[self.get39Index(prev)].append(count)\n",
    "            #-----------------\n",
    "            p_bar.update()\n",
    "            if(i%100==0):\n",
    "                gc.collect()\n",
    "           \n",
    "        feature_vectors = [np.asarray(np.array(feature_vectors[i],dtype=object)).astype(np.float32) for i in range(39)]\n",
    "        print(f\"length of feature_vectors is {feature_vectors[0].shape}\")\n",
    "        return feature_vectors,lengths  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T00:40:15.520469Z",
     "iopub.status.busy": "2021-12-11T00:40:15.519622Z",
     "iopub.status.idle": "2021-12-11T01:14:42.339086Z",
     "shell.execute_reply": "2021-12-11T01:14:42.338348Z",
     "shell.execute_reply.started": "2021-12-11T00:40:15.520419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read features file /kaggle/input/timit-gmmhmm-asr/\n",
      "--- Failed\n",
      "Collecting Features from Audio Files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66e992a547b44cea7514b9f06ec580e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature_vectors is (74738, 64)\n",
      "--- Completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = FeatureCollection(path)\n",
    "n_mels = 64\n",
    "delta = False\n",
    "delta_delta = False\n",
    "ftype = 'mfcc'\n",
    "\n",
    "print('Collecting Features from Audio Files')\n",
    "features,lengths = fc.collectHMMFeatures(ftype=ftype,n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n",
    "# -------------\n",
    "ffp = open(\"/timit-gmmhmm/features.pkl\",'wb')\n",
    "pkl.dump(features,ffp)\n",
    "flp = open(\"/timit-gmmhmm/lengths.pkl\",'wb')\n",
    "pkl.dump(lengths,flp) \n",
    "ffp.close()\n",
    "flp.close()\n",
    "print('--- Completed')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T01:15:58.320626Z",
     "iopub.status.busy": "2021-12-11T01:15:58.319777Z",
     "iopub.status.idle": "2021-12-11T01:48:43.104758Z",
     "shell.execute_reply": "2021-12-11T01:48:43.103763Z",
     "shell.execute_reply.started": "2021-12-11T01:15:58.320580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ade68a72c154aad87b99291fc3ce132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [GMMHMM(n_components=2,n_mix=1,verbose=False,n_iter=15) for i in range(39)]\n",
    "\n",
    "p_bar = tqdm(range(39))\n",
    "\n",
    "# train models\n",
    "for i in range(39):\n",
    "    p_bar.set_description('{}. Training \"{}\" Phoneme Model'.format(i,fc.get39Phon(i)))\n",
    "    models[i].fit(features[i],lengths[i])\n",
    "    p_bar.update()\n",
    "gc.collect()\n",
    "\n",
    "# save models\n",
    "for i in range(39):\n",
    "    filename = \"Model{}-{}.pkl\".format(i,fc.get39Phon(i))\n",
    "    file_handle = open('/timit-gmmhmm/{}'.format(filename),'wb')\n",
    "    pkl.dump(models[i],file_handle)\n",
    "    file_handle.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T01:48:43.106982Z",
     "iopub.status.busy": "2021-12-11T01:48:43.106630Z",
     "iopub.status.idle": "2021-12-11T02:01:50.001008Z",
     "shell.execute_reply": "2021-12-11T02:01:50.000302Z",
     "shell.execute_reply.started": "2021-12-11T01:48:43.106946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25627621f80045a5813b66ef8ae0236f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature_vectors is (28617, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features,test_lengths = fc.collectHMMFeatures(ft='Test',ftype=ftype,n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n",
    "pkl.dump(test_features,open('/timit-gmmhmm/test_features.pkl','wb'))\n",
    "pkl.dump(test_lengths,open('/timit-gmmhmm/test_lengths.pkl','wb'))\n",
    "gc.collect()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T02:01:50.003250Z",
     "iopub.status.busy": "2021-12-11T02:01:50.002976Z",
     "iopub.status.idle": "2021-12-11T02:31:16.038311Z",
     "shell.execute_reply": "2021-12-11T02:31:16.037533Z",
     "shell.execute_reply.started": "2021-12-11T02:01:50.003216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a8bababb434819a7b99264d14aee0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Testing Data of phoneme \"aa\" against all models \n",
      "Result: 469/2347 correct prediction;\n",
      " accuracy: 19.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34fd0f515cf4e52a32b4157f6bd34d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Testing Data of phoneme \"ae\" against all models \n",
      "Result: 30/1433 correct prediction;\n",
      " accuracy: 2.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730fb41e8f69474fbf781921ad4122bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Testing Data of phoneme \"ah\" against all models \n",
      "Result: 384/2426 correct prediction;\n",
      " accuracy: 15.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4638aaef3e4221ac26579b8f380be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Testing Data of phoneme \"aw\" against all models \n",
      "Result: 184/218 correct prediction;\n",
      " accuracy: 84.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b110a7736a424751927ae33c4049a35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Testing Data of phoneme \"ay\" against all models \n",
      "Result: 0/870 correct prediction;\n",
      " accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038eb89927084281a7fd8e5493d58a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Testing Data of phoneme \"b\" against all models \n",
      "Result: 123/497 correct prediction;\n",
      " accuracy: 24.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e00aedcb054313b6339459612e4f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Testing Data of phoneme \"ch\" against all models \n",
      "Result: 211/268 correct prediction;\n",
      " accuracy: 78.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccca87d541254be88d52155140bc8ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. Testing Data of phoneme \"d\" against all models \n",
      "Result: 6/998 correct prediction;\n",
      " accuracy: 0.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1779e79961a34878a5c3c6c270cbcdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1008 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. Testing Data of phoneme \"dh\" against all models \n",
      "Result: 835/1008 correct prediction;\n",
      " accuracy: 82.84%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec70df5af2e142eeb54958c832d641db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. Testing Data of phoneme \"dx\" against all models \n",
      "Result: 623/920 correct prediction;\n",
      " accuracy: 67.72%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48cff221b9649689e9095a282c683e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1471 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11. Testing Data of phoneme \"eh\" against all models \n",
      "Result: 297/1471 correct prediction;\n",
      " accuracy: 20.19%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5729a9f90ad64f728c208851c1760fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12. Testing Data of phoneme \"er\" against all models \n",
      "Result: 1865/2229 correct prediction;\n",
      " accuracy: 83.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ead5708edc403a9e0e8fdb8fc95ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13. Testing Data of phoneme \"ey\" against all models \n",
      "Result: 154/824 correct prediction;\n",
      " accuracy: 18.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11df2170ec684aae810807bee3497765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/924 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14. Testing Data of phoneme \"f\" against all models \n",
      "Result: 465/924 correct prediction;\n",
      " accuracy: 50.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12b3ccf5b1b4eba9d07913a33b40bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15. Testing Data of phoneme \"g\" against all models \n",
      "Result: 178/706 correct prediction;\n",
      " accuracy: 25.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45557d1b16c54450a57a20cc5720e4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16. Testing Data of phoneme \"h#\" against all models \n",
      "Result: 10129/13422 correct prediction;\n",
      " accuracy: 75.47%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eba270c3b6a4be085ca62ef2522148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17. Testing Data of phoneme \"hh\" against all models \n",
      "Result: 620/735 correct prediction;\n",
      " accuracy: 84.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a6eded714f48e9893e456e47b547c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18. Testing Data of phoneme \"ih\" against all models \n",
      "Result: 4314/4812 correct prediction;\n",
      " accuracy: 89.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec632e12365b4d5f9a761be486b7802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19. Testing Data of phoneme \"iy\" against all models \n",
      "Result: 586/2785 correct prediction;\n",
      " accuracy: 21.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445e904f5f124a32b69d3ff9fcaf4135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20. Testing Data of phoneme \"jh\" against all models \n",
      "Result: 229/381 correct prediction;\n",
      " accuracy: 60.10%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3798d49883c49868139ec17607aa6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21. Testing Data of phoneme \"k\" against all models \n",
      "Result: 797/1537 correct prediction;\n",
      " accuracy: 51.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521689ba14294b439d4fa2df221f62df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22. Testing Data of phoneme \"l\" against all models \n",
      "Result: 74/2749 correct prediction;\n",
      " accuracy: 2.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd9bbdae73c422cb48b095c5ee6bd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23. Testing Data of phoneme \"m\" against all models \n",
      "Result: 1295/1571 correct prediction;\n",
      " accuracy: 82.43%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5a9b0dcc5d4aedaaffbba2acdfd985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24. Testing Data of phoneme \"n\" against all models \n",
      "Result: 5/3121 correct prediction;\n",
      " accuracy: 0.16%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c069d19206dc43a3926e240dfef8d9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25. Testing Data of phoneme \"ng\" against all models \n",
      "Result: 173/420 correct prediction;\n",
      " accuracy: 41.19%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aff2250c97d45338d1cf897da18b2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26. Testing Data of phoneme \"ow\" against all models \n",
      "Result: 27/814 correct prediction;\n",
      " accuracy: 3.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3656b8fab104dceb37b26a993cbf43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27. Testing Data of phoneme \"oy\" against all models \n",
      "Result: 3/266 correct prediction;\n",
      " accuracy: 1.13%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91b9f5dfcc84ab8b4f9aeb43cefa11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28. Testing Data of phoneme \"p\" against all models \n",
      "Result: 703/888 correct prediction;\n",
      " accuracy: 79.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d474e314f2d64138b41d0ca614a00906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29. Testing Data of phoneme \"r\" against all models \n",
      "Result: 372/2548 correct prediction;\n",
      " accuracy: 14.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a346b3fc7f654902bac426862e0aeeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30. Testing Data of phoneme \"s\" against all models \n",
      "Result: 1760/2699 correct prediction;\n",
      " accuracy: 65.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb226446714419d8c4a3b7f878e3929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31. Testing Data of phoneme \"sh\" against all models \n",
      "Result: 870/875 correct prediction;\n",
      " accuracy: 99.43%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09da800b8620434090eedf7a626f2933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32. Testing Data of phoneme \"t\" against all models \n",
      "Result: 1428/1527 correct prediction;\n",
      " accuracy: 93.52%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f4051b05224d5c8e0d13658ccd79d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33. Testing Data of phoneme \"th\" against all models \n",
      "Result: 57/268 correct prediction;\n",
      " accuracy: 21.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488dfc42569246fc988b93985e5c7d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34. Testing Data of phoneme \"uh\" against all models \n",
      "Result: 1/225 correct prediction;\n",
      " accuracy: 0.44%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c321296c42343aab749717cebaa4911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35. Testing Data of phoneme \"uw\" against all models \n",
      "Result: 462/756 correct prediction;\n",
      " accuracy: 61.11%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518d6d030552478c8cd20e49dd4f6c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36. Testing Data of phoneme \"v\" against all models \n",
      "Result: 575/712 correct prediction;\n",
      " accuracy: 80.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1727db2528341e5af8f0614796b0630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37. Testing Data of phoneme \"w\" against all models \n",
      "Result: 1197/1244 correct prediction;\n",
      " accuracy: 96.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f86976f344045eabd5b3ecd78674935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38. Testing Data of phoneme \"y\" against all models \n",
      "Result: 62/653 correct prediction;\n",
      " accuracy: 9.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5873c2781e3a4f2aaf44c6fd98ed6104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39. Testing Data of phoneme \"z\" against all models \n",
      "Result: 1010/1278 correct prediction;\n",
      " accuracy: 79.03%\n"
     ]
    }
   ],
   "source": [
    "for i in range(39):\n",
    "    # --- adding missing length at end\n",
    "    tfeat_len = test_features[i].shape[0]\n",
    "    tlen_len = np.sum(test_lengths[i])\n",
    "    if tfeat_len != tlen_len:\n",
    "        test_lengths[i].append(tfeat_len-tlen_len)\n",
    "\n",
    "predictions = []\n",
    "for i in range(39):\n",
    "    #for each phon data\n",
    "    count = 0\n",
    "    s = 0\n",
    "    p_bar = tqdm(range(len(test_lengths[i])))\n",
    "    p_bar.set_description('{}. Testing Data of phoneme \"{}\" against all models'.format(i,fc.get39Phon(i)))\n",
    "    \n",
    "    for j in test_lengths[i]:\n",
    "        # test in each phon model\n",
    "        max_prediction = -999999999999\n",
    "        max_index = 0\n",
    "        t_feat = test_features[i][s:j+s]\n",
    "        for k in range(39):\n",
    "            try:\n",
    "                score = math.floor(models[k].score(t_feat)*1000)\n",
    "                if(score > max_prediction):\n",
    "                    max_prediction = score\n",
    "                    max_index = k\n",
    "                if max_index > i:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        p_bar.update() \n",
    "        count+= 1 if max_index == i else 0      \n",
    "        s=j\n",
    "        \n",
    "    predictions.append((count,len(test_lengths[i])))\n",
    "    \n",
    "    p_bar.set_description('{}. Testing Data of phoneme \"{}\" against all models \\nResult: {}/{} correct prediction;\\n accuracy: {:.2f}%'.format(\n",
    "        i+1,fc.get39Phon(i),count,len(test_lengths[i]),(count/len(test_lengths[i]))*100)\n",
    "    )\n",
    "    print('{}. Testing Data of phoneme \"{}\" against all models \\nResult: {}/{} correct prediction;\\n accuracy: {:.2f}%'.format(\n",
    "        i+1,fc.get39Phon(i),count,len(test_lengths[i]),(count/len(test_lengths[i]))*100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T02:31:16.040929Z",
     "iopub.status.busy": "2021-12-11T02:31:16.040351Z",
     "iopub.status.idle": "2021-12-11T02:31:16.063048Z",
     "shell.execute_reply": "2021-12-11T02:31:16.062149Z",
     "shell.execute_reply.started": "2021-12-11T02:31:16.040889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy is 45.863348%\n",
      "Total Accuracy is 51.356721%\n",
      "Individual Accuracy:\n",
      "Accuracy of \"aa\" Model:  19.98295696634001\n",
      "Accuracy of \"ae\" Model:  2.09351011863224\n",
      "Accuracy of \"ah\" Model:  15.828524319868094\n",
      "Accuracy of \"aw\" Model:  84.40366972477065\n",
      "Accuracy of \"ay\" Model:  0.0\n",
      "Accuracy of \"b\" Model:  24.748490945674046\n",
      "Accuracy of \"ch\" Model:  78.73134328358209\n",
      "Accuracy of \"d\" Model:  0.6012024048096193\n",
      "Accuracy of \"dh\" Model:  82.8373015873016\n",
      "Accuracy of \"dx\" Model:  67.71739130434783\n",
      "Accuracy of \"eh\" Model:  20.190346702923183\n",
      "Accuracy of \"er\" Model:  83.66980708838044\n",
      "Accuracy of \"ey\" Model:  18.689320388349515\n",
      "Accuracy of \"f\" Model:  50.324675324675326\n",
      "Accuracy of \"g\" Model:  25.21246458923513\n",
      "Accuracy of \"h#\" Model:  75.46565340485769\n",
      "Accuracy of \"hh\" Model:  84.35374149659864\n",
      "Accuracy of \"ih\" Model:  89.6508728179551\n",
      "Accuracy of \"iy\" Model:  21.04129263913824\n",
      "Accuracy of \"jh\" Model:  60.10498687664042\n",
      "Accuracy of \"k\" Model:  51.85426154847105\n",
      "Accuracy of \"l\" Model:  2.691887959257912\n",
      "Accuracy of \"m\" Model:  82.43157224697644\n",
      "Accuracy of \"n\" Model:  0.16020506247997437\n",
      "Accuracy of \"ng\" Model:  41.19047619047619\n",
      "Accuracy of \"ow\" Model:  3.3169533169533167\n",
      "Accuracy of \"oy\" Model:  1.1278195488721803\n",
      "Accuracy of \"p\" Model:  79.16666666666666\n",
      "Accuracy of \"r\" Model:  14.599686028257459\n",
      "Accuracy of \"s\" Model:  65.20933679140423\n",
      "Accuracy of \"sh\" Model:  99.42857142857143\n",
      "Accuracy of \"t\" Model:  93.51669941060904\n",
      "Accuracy of \"th\" Model:  21.26865671641791\n",
      "Accuracy of \"uh\" Model:  0.4444444444444444\n",
      "Accuracy of \"uw\" Model:  61.111111111111114\n",
      "Accuracy of \"v\" Model:  80.75842696629213\n",
      "Accuracy of \"w\" Model:  96.22186495176848\n",
      "Accuracy of \"y\" Model:  9.494640122511486\n",
      "Accuracy of \"z\" Model:  79.02973395931141\n"
     ]
    }
   ],
   "source": [
    "t_correct = 0\n",
    "t_length = 0\n",
    "for x,y in predictions:\n",
    "    t_correct+=x\n",
    "    t_length+= y\n",
    "\n",
    "print(\"Mean Accuracy is {:2f}%\".format((np.sum([x/y for x,y in predictions])/39)*100))\n",
    "print(\"Total Accuracy is {:2f}%\".format((t_correct/t_length)*100))\n",
    "print('Individual Accuracy:')\n",
    "for i in range(39):\n",
    "    x = predictions[i][0]\n",
    "    y = predictions[i][1]\n",
    "    print(f\"Accuracy of \\\"{fc.get39Phon(i)}\\\" Model: \",(x/y)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
